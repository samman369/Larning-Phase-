{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa68GGfji3tL",
        "outputId": "f7bd1db2-295a-48aa-e7ca-c6a365f2ac28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m122.9/129.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7k7WJjKdYg-n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56746020-5362-4831-dfc5-cc41be432d7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n"
          ]
        }
      ],
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "import keras_tuner\n",
        "\n",
        "def model_built(hp):\n",
        "  model = keras.Sequential()\n",
        "  model.add(layers.Flatten())\n",
        "  # we will do hyperperemeter in first layer only\n",
        "  model.add(layers.Dense(\n",
        "      units = hp.Int(\"units\", min_value = 10, max_value = 512, step =30),\n",
        "      activation = hp.Choice(\"activation\", [\"relu\", \"softmax\", \"tanh\"])\n",
        "    )\n",
        "  )\n",
        "  # tune wheather to use dropout\n",
        "  if hp.Boolean(\"dropout\"):\n",
        "    model.add(layers.Dropout(rate=0.25))\n",
        "\n",
        "  model.add(layers.Dense(10, activation=\"softmax\"))\n",
        "  # here we use learning rate\n",
        "  learning_rate = hp.Float(\"lr\", min_value = 1e-4, max_value = 1e-2, sampling=\"log\")\n",
        "\n",
        "  model.compile(\n",
        "        optimizer =keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "        loss = \"categorical_crossentropy\",\n",
        "        metrics = [\"accuracy\"]\n",
        "     )\n",
        "  return model\n",
        "\n",
        "model_built(keras_tuner.HyperParameters())\n",
        "\n",
        "# lets see what is 'hp.Int' function\n",
        "hp = keras_tuner.HyperParameters()\n",
        "print(hp.Int(\"units\", min_value = 10, max_value = 512, step =30))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We can also create hyperparameter and kares code in seperate\n",
        "\n",
        "def keras_model(units, activation, dropout, lr):\n",
        "  model = keras.Sequential()\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(\n",
        "      units = units,\n",
        "      activation = activation,\n",
        "  ))\n",
        "  model.add(layers.Dropout(rate=0.25))\n",
        "  model.add(layers.Dense(10, activation='relu'))\n",
        "\n",
        "  model.compile(\n",
        "      optimizer = keras.optimizers.Adam(learning_rate=lr),\n",
        "      loss = \"catagorical_crossentropy\",\n",
        "      metrics = [\"accuracy\"],\n",
        "  )\n",
        "\n",
        "  return model\n",
        "\n",
        "# here we seperate the hyperparameter\n",
        "def built_model(hp):\n",
        "  units = hp.Int(\"units\", min_value=10, max_value=512, step = 32),\n",
        "  activation = hp.Choice(\"activation\", [\"relu\",\"softmax\",\"tanh\"])\n",
        "  dropout = hp.Boolean('dropout')\n",
        "  lr = hp.Float(\"lr\", min_value = 1e-4, max_value=1e-2, sampling=\"log\")\n",
        "\n",
        "  model = keras_model(\n",
        "      units=units,\n",
        "      activation=activation,\n",
        "      dropout=0.25,\n",
        "      lr=lr)\n",
        "  return model\n",
        "\n",
        "built_model(keras_tuner.HyperParameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuOsA--2jm5H",
        "outputId": "01c51772-3315-438f-a04a-5e432f4f616b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Sequential name=sequential_9, built=False>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# here our main aim is to tune the number of hidden layer\n",
        "def build_model_with_tunning_layers(hp):\n",
        "    model = keras.Sequential()\n",
        "    model.add(layers.Flatten())\n",
        "\n",
        "    # Tune the number of layers.\n",
        "    for i in range(hp.Int(\"total_layer\", 1, 25)):\n",
        "      model.add(\n",
        "          layers.Dense(\n",
        "              units= hp.Int(f\"unit_{i}\", min_value=10, max_value=512, step=30),\n",
        "              activation = hp.Choice(\"activation\", [\"relu\", \"softmax\",\"tanh\"])\n",
        "          )\n",
        "      )\n",
        "\n",
        "    if hp.Boolean(\"dropout\"):\n",
        "        model.add(layers.Dropout(rate=0.25))\n",
        "    model.add(layers.Dense(10, activation=\"softmax\"))\n",
        "    learning_rate = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "        loss=\"categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "build_model_with_tunning_layers(keras_tuner.HyperParameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLgv6ppNpXhS",
        "outputId": "94e896da-4bd6-4fcf-a45b-1c227b349a79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Sequential name=sequential_13, built=False>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# start the search\n",
        "tuner = keras_tuner.RandomSearch(\n",
        "    hypermodel = build_model_with_tunning_layers,\n",
        "    objective = \"val_accuracy\",\n",
        "    max_trials= 2,\n",
        "    executions_per_trial = 5,\n",
        "    overwrite = \"True\",\n",
        "    directory = \" my_dict\",\n",
        "    project_name = \"hello world\"\n",
        ")\n",
        "\n",
        "tuner.search_space_summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-rOYBN7t72T",
        "outputId": "a7a937bb-3643-4b84-d3f4-bf8196ec62e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search space summary\n",
            "Default search space size: 5\n",
            "total_layer (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 25, 'step': 1, 'sampling': 'linear'}\n",
            "unit_0 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 10, 'max_value': 512, 'step': 30, 'sampling': 'linear'}\n",
            "activation (Choice)\n",
            "{'default': 'relu', 'conditions': [], 'values': ['relu', 'softmax', 'tanh'], 'ordered': False}\n",
            "dropout (Boolean)\n",
            "{'default': False, 'conditions': []}\n",
            "lr (Float)\n",
            "{'default': 0.0001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare the dataset first\n"
      ],
      "metadata": {
        "id": "GRyAvse-weCq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "\n",
        "(x, y), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "x_train = x[:-10000]\n",
        "x_val = x[-10000:]\n",
        "y_train = y[:-10000]\n",
        "y_val = y[-10000:]\n",
        "\n",
        "x_train = np.expand_dims(x_train, -1).astype(\"float32\") / 255.0\n",
        "x_val = np.expand_dims(x_val, -1).astype(\"float32\") / 255.0\n",
        "x_test = np.expand_dims(x_test, -1).astype(\"float32\") / 255.0\n",
        "\n",
        "num_classes = 10\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgSLmbIlvmbg",
        "outputId": "5bee0986-1cd5-4f56-f909-e583798bda8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(x_train, y_train, epochs=2, validation_data=(x_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaMofV8uwjSS",
        "outputId": "7e3fdc45-3a83-4774-e659-884633501159"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 2 Complete [00h 02m 57s]\n",
            "val_accuracy: 0.9622200131416321\n",
            "\n",
            "Best val_accuracy So Far: 0.9622200131416321\n",
            "Total elapsed time: 00h 06m 45s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  show the output of best model\n",
        "models = tuner.get_best_models(num_models=2)\n",
        "best_model = models[0]\n",
        "best_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "id": "uowU0nvswojO",
        "outputId": "ea4272cb-079e-469f-ee71-2c64ed41fe32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 22 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 78 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m70\u001b[0m)                  │          \u001b[38;5;34m54,950\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)                  │           \u001b[38;5;34m2,840\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m460\u001b[0m)                 │          \u001b[38;5;34m18,860\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m340\u001b[0m)                 │         \u001b[38;5;34m156,740\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m3,410\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">54,950</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,840</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">460</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,860</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">340</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">156,740</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,410</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m236,800\u001b[0m (925.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">236,800</span> (925.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m236,800\u001b[0m (925.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">236,800</span> (925.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.results_summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dEOtUp8y99D",
        "outputId": "6b51e070-5ef6-4fef-9d33-553d422fe395"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results summary\n",
            "Results in  my_dict/hello world\n",
            "Showing 10 best trials\n",
            "Objective(name=\"val_accuracy\", direction=\"max\")\n",
            "\n",
            "Trial 1 summary\n",
            "Hyperparameters:\n",
            "total_layer: 4\n",
            "unit_0: 70\n",
            "activation: relu\n",
            "dropout: False\n",
            "lr: 0.001024143840053108\n",
            "unit_1: 40\n",
            "unit_2: 460\n",
            "unit_3: 340\n",
            "unit_4: 310\n",
            "unit_5: 490\n",
            "unit_6: 340\n",
            "unit_7: 400\n",
            "unit_8: 40\n",
            "unit_9: 160\n",
            "unit_10: 130\n",
            "unit_11: 310\n",
            "unit_12: 40\n",
            "unit_13: 490\n",
            "unit_14: 100\n",
            "unit_15: 370\n",
            "unit_16: 280\n",
            "unit_17: 130\n",
            "Score: 0.9622200131416321\n",
            "\n",
            "Trial 0 summary\n",
            "Hyperparameters:\n",
            "total_layer: 18\n",
            "unit_0: 310\n",
            "activation: relu\n",
            "dropout: True\n",
            "lr: 0.0007359237843776363\n",
            "unit_1: 10\n",
            "unit_2: 10\n",
            "unit_3: 10\n",
            "unit_4: 10\n",
            "unit_5: 10\n",
            "unit_6: 10\n",
            "unit_7: 10\n",
            "unit_8: 10\n",
            "unit_9: 10\n",
            "unit_10: 10\n",
            "unit_11: 10\n",
            "unit_12: 10\n",
            "unit_13: 10\n",
            "unit_14: 10\n",
            "unit_15: 10\n",
            "unit_16: 10\n",
            "unit_17: 10\n",
            "Score: 0.4342000037431717\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# retrain the model\n",
        "\n",
        "# Get the top 2 hyperparameters.\n",
        "best_hps = tuner.get_best_hyperparameters(5)\n",
        "# Build the model with the best hp.\n",
        "model = build_model(best_hps[0])\n",
        "# Fit with the entire dataset.\n",
        "x_all = np.concatenate((x_train, x_val))\n",
        "y_all = np.concatenate((y_train, y_val))\n",
        "model.fit(x=x_all, y=y_all, epochs=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOCPHcz60YlO",
        "outputId": "4e2b63ad-62b1-443a-99e9-656bfbefce58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.8703 - loss: 0.4145\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x796a5c3392d0>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GWxD0tGi1J5h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}